{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1. SET-UP**"
      ],
      "metadata": {
        "id": "_LQM-XuRZr96"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0xeKyJrRaEV",
        "outputId": "42227413-0f5c-40cc-f4c2-5b07ed1d3c95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/sample_data/MyDrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/sample_data/MyDrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "-tCQwNkmRyfU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. DATA LOADING**"
      ],
      "metadata": {
        "id": "-aOljfaZZ3ki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = ('/content/sample_data/MyDrive/MyDrive/lane_classifier/data')\n",
        "dataset = tf.keras.utils.image_dataset_from_directory(data_dir, label_mode='categorical',batch_size = 64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upYlpnNJR0vx",
        "outputId": "4a0db82e-b19a-483c-a459-733ebf1170a7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2287 files belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_iterator = dataset.as_numpy_iterator()\n",
        "batch = data_iterator.next()"
      ],
      "metadata": {
        "id": "j2iq3SiQSF-o"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9vI2gkeSJS4",
        "outputId": "9bcc6938-342f-4c7e-e07f-e7602190313b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def resize_function(x, y):\n",
        "    resized_x = tf.image.resize(x, (224, 224))\n",
        "\n",
        "    return resized_x, y\n",
        "\n",
        "# Apply the resize function to each element in the dataset\n",
        "dataset = dataset.map(resize_function)\n",
        "\n",
        "dataset = dataset.map(lambda x,y : (x/255,y))"
      ],
      "metadata": {
        "id": "Fg-1huSOSTLI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_iterator = dataset.as_numpy_iterator()\n",
        "scaled_batch = scaled_iterator.next()\n",
        "scaled_batch[0].max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U24TShrISVuh",
        "outputId": "9a518105-4842-4aaa-80c4-cf93a4ca63f5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(len(dataset)*.7)+1\n",
        "val_size = int(len(dataset)*.1)+2\n",
        "test_size = int(len(dataset)*.1)+2"
      ],
      "metadata": {
        "id": "ETndtHitSkBv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = dataset.take(train_size)\n",
        "val_data = dataset.skip(train_size).take(val_size)\n",
        "test_data = dataset.skip(train_size+val_size).take(test_size)"
      ],
      "metadata": {
        "id": "2XKosl1USmLg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features_labels(image, label):\n",
        "    return image, label\n",
        "\n",
        "x_train, y_train = zip(*train_data.map(extract_features_labels))\n",
        "x_val, y_val = zip(*val_data.map(extract_features_labels))\n",
        "x_test, y_test = zip(*test_data.map(extract_features_labels))"
      ],
      "metadata": {
        "id": "zlccB3IIWXt-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = tf.concat(x_train, axis=0).numpy()\n",
        "y_train = tf.concat(y_train, axis=0).numpy()\n",
        "x_val = tf.concat(x_val, axis=0).numpy()\n",
        "y_val = tf.concat(y_val, axis=0).numpy()\n",
        "x_test = tf.concat(x_test, axis=0).numpy()\n",
        "y_test = tf.concat(y_test, axis=0).numpy()"
      ],
      "metadata": {
        "id": "j1WX80qVWfSt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# data augmentation\n",
        "aug = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.15,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\")\n"
      ],
      "metadata": {
        "id": "PqCtolXfWhlO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. MODEL ARCHITECTURE**"
      ],
      "metadata": {
        "id": "Be-37JHbZ_YH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPooling2D, Dropout, BatchNormalization"
      ],
      "metadata": {
        "id": "4KV1zZmiX9bf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# original\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, (3,3), 1, activation = 'relu', input_shape = (224,224,3)))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(32, (3,3), 1, activation = 'relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Conv2D(16, (3,3), 1, activation = 'relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense( 256, activation = \"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense( 3, activation = 'softmax'))\n"
      ],
      "metadata": {
        "id": "Q6RbfcnOYBt6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics = ['accuracy'] )\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mm_8_c3Zc6x",
        "outputId": "cf7a8c1e-c136-4fc5-a1a7-051e2c6f097c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 222, 222, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 111, 111, 16)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 109, 109, 32)      4640      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 54, 54, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 52, 52, 16)        4624      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 26, 26, 16)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 10816)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               2769152   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 771       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2779635 (10.60 MB)\n",
            "Trainable params: 2779635 (10.60 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LR = 0.0001"
      ],
      "metadata": {
        "id": "ANZoQW0rbJac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
        "\n",
        "def lr_scheduler(epoch):\n",
        "    return 0.0001 * (0.5 ** (epoch // 20))\n",
        "reduce_lr = LearningRateScheduler(lr_scheduler)\n",
        "\n",
        "mc = ModelCheckpoint('./weights.h5', monitor='val_accuracy', save_best_only=True, mode='max')\n"
      ],
      "metadata": {
        "id": "NwaHxcjJYUdE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lr = 0.0001\n",
        "EPOCHS = 30\n",
        "BS = 64\n",
        "\n",
        "history = model.fit(\n",
        "    aug.flow(x_train,y_train, batch_size=BS),\n",
        "    validation_data=(x_val,y_val),\n",
        "    steps_per_epoch=len(x_train) // BS,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[reduce_lr,mc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFxC62q7cIaU",
        "outputId": "a481b2d5-d412-4922-f40d-f2e094960c5c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "26/26 [==============================] - 26s 724ms/step - loss: 0.9712 - accuracy: 0.5643 - val_loss: 0.7575 - val_accuracy: 0.7531 - lr: 1.0000e-04\n",
            "Epoch 2/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26/26 [==============================] - 20s 770ms/step - loss: 0.6461 - accuracy: 0.7800 - val_loss: 0.4527 - val_accuracy: 0.8844 - lr: 1.0000e-04\n",
            "Epoch 3/30\n",
            "26/26 [==============================] - 20s 756ms/step - loss: 0.4094 - accuracy: 0.8894 - val_loss: 0.3052 - val_accuracy: 0.9594 - lr: 1.0000e-04\n",
            "Epoch 4/30\n",
            "26/26 [==============================] - 19s 748ms/step - loss: 0.2314 - accuracy: 0.9519 - val_loss: 0.2125 - val_accuracy: 0.9656 - lr: 1.0000e-04\n",
            "Epoch 5/30\n",
            "26/26 [==============================] - 21s 779ms/step - loss: 0.1386 - accuracy: 0.9669 - val_loss: 0.1702 - val_accuracy: 0.9438 - lr: 1.0000e-04\n",
            "Epoch 6/30\n",
            "26/26 [==============================] - 19s 745ms/step - loss: 0.1006 - accuracy: 0.9724 - val_loss: 0.1464 - val_accuracy: 0.9688 - lr: 1.0000e-04\n",
            "Epoch 7/30\n",
            "26/26 [==============================] - 21s 798ms/step - loss: 0.0809 - accuracy: 0.9814 - val_loss: 0.1156 - val_accuracy: 0.9719 - lr: 1.0000e-04\n",
            "Epoch 8/30\n",
            "26/26 [==============================] - 19s 746ms/step - loss: 0.0691 - accuracy: 0.9826 - val_loss: 0.1157 - val_accuracy: 0.9688 - lr: 1.0000e-04\n",
            "Epoch 9/30\n",
            "26/26 [==============================] - 21s 794ms/step - loss: 0.0558 - accuracy: 0.9820 - val_loss: 0.0968 - val_accuracy: 0.9750 - lr: 1.0000e-04\n",
            "Epoch 10/30\n",
            "26/26 [==============================] - 19s 738ms/step - loss: 0.0359 - accuracy: 0.9922 - val_loss: 0.1132 - val_accuracy: 0.9656 - lr: 1.0000e-04\n",
            "Epoch 11/30\n",
            "26/26 [==============================] - 20s 789ms/step - loss: 0.0307 - accuracy: 0.9916 - val_loss: 0.1037 - val_accuracy: 0.9656 - lr: 1.0000e-04\n",
            "Epoch 12/30\n",
            "26/26 [==============================] - 18s 709ms/step - loss: 0.0346 - accuracy: 0.9892 - val_loss: 0.1145 - val_accuracy: 0.9563 - lr: 1.0000e-04\n",
            "Epoch 13/30\n",
            "26/26 [==============================] - 21s 807ms/step - loss: 0.0328 - accuracy: 0.9898 - val_loss: 0.0547 - val_accuracy: 0.9781 - lr: 1.0000e-04\n",
            "Epoch 14/30\n",
            "26/26 [==============================] - 21s 794ms/step - loss: 0.0231 - accuracy: 0.9970 - val_loss: 0.0629 - val_accuracy: 0.9750 - lr: 1.0000e-04\n",
            "Epoch 15/30\n",
            "26/26 [==============================] - 20s 748ms/step - loss: 0.0162 - accuracy: 0.9970 - val_loss: 0.0418 - val_accuracy: 0.9844 - lr: 1.0000e-04\n",
            "Epoch 16/30\n",
            "26/26 [==============================] - 20s 752ms/step - loss: 0.0127 - accuracy: 0.9994 - val_loss: 0.0665 - val_accuracy: 0.9719 - lr: 1.0000e-04\n",
            "Epoch 17/30\n",
            "26/26 [==============================] - 21s 781ms/step - loss: 0.0136 - accuracy: 0.9964 - val_loss: 0.0456 - val_accuracy: 0.9812 - lr: 1.0000e-04\n",
            "Epoch 18/30\n",
            "26/26 [==============================] - 19s 739ms/step - loss: 0.0177 - accuracy: 0.9976 - val_loss: 0.0373 - val_accuracy: 0.9812 - lr: 1.0000e-04\n",
            "Epoch 19/30\n",
            "26/26 [==============================] - 21s 798ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0604 - val_accuracy: 0.9781 - lr: 1.0000e-04\n",
            "Epoch 20/30\n",
            "26/26 [==============================] - 20s 755ms/step - loss: 0.0125 - accuracy: 0.9982 - val_loss: 0.0236 - val_accuracy: 0.9969 - lr: 1.0000e-04\n",
            "Epoch 21/30\n",
            "26/26 [==============================] - 19s 739ms/step - loss: 0.0142 - accuracy: 0.9964 - val_loss: 0.0255 - val_accuracy: 0.9969 - lr: 5.0000e-05\n",
            "Epoch 22/30\n",
            "26/26 [==============================] - 21s 798ms/step - loss: 0.0080 - accuracy: 0.9994 - val_loss: 0.0319 - val_accuracy: 0.9906 - lr: 5.0000e-05\n",
            "Epoch 23/30\n",
            "26/26 [==============================] - 20s 746ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.0230 - val_accuracy: 0.9969 - lr: 5.0000e-05\n",
            "Epoch 24/30\n",
            "26/26 [==============================] - 19s 731ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0308 - val_accuracy: 0.9906 - lr: 5.0000e-05\n",
            "Epoch 25/30\n",
            "26/26 [==============================] - 19s 716ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0343 - val_accuracy: 0.9812 - lr: 5.0000e-05\n",
            "Epoch 26/30\n",
            "26/26 [==============================] - 19s 738ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 0.0394 - val_accuracy: 0.9812 - lr: 5.0000e-05\n",
            "Epoch 27/30\n",
            "26/26 [==============================] - 21s 798ms/step - loss: 0.0103 - accuracy: 0.9982 - val_loss: 0.0328 - val_accuracy: 0.9812 - lr: 5.0000e-05\n",
            "Epoch 28/30\n",
            "26/26 [==============================] - 19s 720ms/step - loss: 0.0065 - accuracy: 0.9994 - val_loss: 0.0253 - val_accuracy: 0.9969 - lr: 5.0000e-05\n",
            "Epoch 29/30\n",
            "26/26 [==============================] - 21s 795ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.0272 - val_accuracy: 0.9969 - lr: 5.0000e-05\n",
            "Epoch 30/30\n",
            "26/26 [==============================] - 19s 742ms/step - loss: 0.0081 - accuracy: 0.9988 - val_loss: 0.0315 - val_accuracy: 0.9844 - lr: 5.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LR = 0.01"
      ],
      "metadata": {
        "id": "0MNCFzi5bPtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
        "\n",
        "def lr_scheduler(epoch):\n",
        "    return 0.0001 * (0.5 ** (epoch // 20))\n",
        "reduce_lr = LearningRateScheduler(lr_scheduler)\n",
        "\n",
        "mc = ModelCheckpoint('./weights.h5', monitor='val_accuracy', save_best_only=True, mode='max')\n"
      ],
      "metadata": {
        "id": "1UeMJYE1bH0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lr = 0.01\n",
        "EPOCHS = 30\n",
        "BS = 64\n",
        "\n",
        "history = model.fit(\n",
        "    aug.flow(x_train,y_train, batch_size=BS),\n",
        "    validation_data=(x_val,y_val),\n",
        "    steps_per_epoch=len(x_train) // BS,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[reduce_lr,mc])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXz4ZOYWcYlq",
        "outputId": "bf97a27d-8ecd-4f7c-8525-7c710a3f80fc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "26/26 [==============================] - 20s 766ms/step - loss: 23.3698 - accuracy: 0.4645 - val_loss: 1.0752 - val_accuracy: 0.4469 - lr: 0.0100\n",
            "Epoch 2/30\n",
            "26/26 [==============================] - 20s 772ms/step - loss: 1.0655 - accuracy: 0.4615 - val_loss: 1.0732 - val_accuracy: 0.4469 - lr: 0.0100\n",
            "Epoch 3/30\n",
            "26/26 [==============================] - 19s 747ms/step - loss: 1.0594 - accuracy: 0.4615 - val_loss: 1.0751 - val_accuracy: 0.4469 - lr: 0.0100\n",
            "Epoch 4/30\n",
            "26/26 [==============================] - 20s 757ms/step - loss: 1.0612 - accuracy: 0.4615 - val_loss: 1.0724 - val_accuracy: 0.4469 - lr: 0.0100\n",
            "Epoch 5/30\n",
            "26/26 [==============================] - 19s 739ms/step - loss: 1.0598 - accuracy: 0.4615 - val_loss: 1.0747 - val_accuracy: 0.4469 - lr: 0.0100\n",
            "Epoch 6/30\n",
            "26/26 [==============================] - 20s 754ms/step - loss: 1.0585 - accuracy: 0.4615 - val_loss: 1.0758 - val_accuracy: 0.4469 - lr: 0.0100\n",
            "Epoch 7/30\n",
            "26/26 [==============================] - 20s 743ms/step - loss: 1.0599 - accuracy: 0.4615 - val_loss: 1.0731 - val_accuracy: 0.4469 - lr: 0.0100\n",
            "Epoch 8/30\n",
            "26/26 [==============================] - 20s 760ms/step - loss: 1.0589 - accuracy: 0.4615 - val_loss: 1.0753 - val_accuracy: 0.4469 - lr: 0.0100\n",
            "Epoch 9/30\n",
            "26/26 [==============================] - 20s 733ms/step - loss: 1.0587 - accuracy: 0.4615 - val_loss: 1.0742 - val_accuracy: 0.4469 - lr: 0.0100\n",
            "Epoch 10/30\n",
            "26/26 [==============================] - 19s 738ms/step - loss: 1.0599 - accuracy: 0.4615 - val_loss: 1.0741 - val_accuracy: 0.4469 - lr: 0.0100\n",
            "Epoch 11/30\n",
            "26/26 [==============================] - 21s 795ms/step - loss: 1.0592 - accuracy: 0.4615 - val_loss: 1.0745 - val_accuracy: 0.4469 - lr: 0.0100\n",
            "Epoch 12/30\n",
            "26/26 [==============================] - 20s 751ms/step - loss: 1.0594 - accuracy: 0.4615 - val_loss: 1.0753 - val_accuracy: 0.4469 - lr: 0.0100\n",
            "Epoch 13/30\n",
            "26/26 [==============================] - 19s 734ms/step - loss: 1.0593 - accuracy: 0.4615 - val_loss: 1.0731 - val_accuracy: 0.4469 - lr: 0.0100\n",
            "Epoch 14/30\n",
            "26/26 [==============================] - 21s 812ms/step - loss: 1.0586 - accuracy: 0.4615 - val_loss: 1.0754 - val_accuracy: 0.4469 - lr: 0.0100\n",
            "Epoch 15/30\n",
            "26/26 [==============================] - 19s 749ms/step - loss: 1.0589 - accuracy: 0.4615 - val_loss: 1.0743 - val_accuracy: 0.4469 - lr: 0.0100\n",
            "Epoch 16/30\n",
            "26/26 [==============================] - 21s 806ms/step - loss: 1.0588 - accuracy: 0.4615 - val_loss: 1.0738 - val_accuracy: 0.4469 - lr: 0.0100\n",
            "Epoch 17/30\n",
            "26/26 [==============================] - 21s 789ms/step - loss: 1.0589 - accuracy: 0.4615 - val_loss: 1.0746 - val_accuracy: 0.4469 - lr: 0.0100\n",
            "Epoch 18/30\n",
            "26/26 [==============================] - 19s 750ms/step - loss: 1.0589 - accuracy: 0.4615 - val_loss: 1.0749 - val_accuracy: 0.4469 - lr: 0.0100\n",
            "Epoch 19/30\n",
            "26/26 [==============================] - 21s 807ms/step - loss: 1.0589 - accuracy: 0.4615 - val_loss: 1.0748 - val_accuracy: 0.4469 - lr: 0.0100\n",
            "Epoch 20/30\n",
            "26/26 [==============================] - 21s 804ms/step - loss: 1.0591 - accuracy: 0.4615 - val_loss: 1.0739 - val_accuracy: 0.4469 - lr: 0.0100\n",
            "Epoch 21/30\n",
            "26/26 [==============================] - 21s 794ms/step - loss: 1.0587 - accuracy: 0.4615 - val_loss: 1.0742 - val_accuracy: 0.4469 - lr: 0.0050\n",
            "Epoch 22/30\n",
            "26/26 [==============================] - 19s 738ms/step - loss: 1.0587 - accuracy: 0.4615 - val_loss: 1.0749 - val_accuracy: 0.4469 - lr: 0.0050\n",
            "Epoch 23/30\n",
            "26/26 [==============================] - 21s 800ms/step - loss: 1.0587 - accuracy: 0.4615 - val_loss: 1.0741 - val_accuracy: 0.4469 - lr: 0.0050\n",
            "Epoch 24/30\n",
            "26/26 [==============================] - 21s 796ms/step - loss: 1.0586 - accuracy: 0.4615 - val_loss: 1.0746 - val_accuracy: 0.4469 - lr: 0.0050\n",
            "Epoch 25/30\n",
            "26/26 [==============================] - 20s 749ms/step - loss: 1.0586 - accuracy: 0.4615 - val_loss: 1.0741 - val_accuracy: 0.4469 - lr: 0.0050\n",
            "Epoch 26/30\n",
            "26/26 [==============================] - 19s 732ms/step - loss: 1.0586 - accuracy: 0.4615 - val_loss: 1.0743 - val_accuracy: 0.4469 - lr: 0.0050\n",
            "Epoch 27/30\n",
            "26/26 [==============================] - 21s 776ms/step - loss: 1.0587 - accuracy: 0.4615 - val_loss: 1.0742 - val_accuracy: 0.4469 - lr: 0.0050\n",
            "Epoch 28/30\n",
            "26/26 [==============================] - 19s 727ms/step - loss: 1.0585 - accuracy: 0.4615 - val_loss: 1.0743 - val_accuracy: 0.4469 - lr: 0.0050\n",
            "Epoch 29/30\n",
            "26/26 [==============================] - 19s 736ms/step - loss: 1.0587 - accuracy: 0.4615 - val_loss: 1.0745 - val_accuracy: 0.4469 - lr: 0.0050\n",
            "Epoch 30/30\n",
            "26/26 [==============================] - 20s 769ms/step - loss: 1.0586 - accuracy: 0.4615 - val_loss: 1.0746 - val_accuracy: 0.4469 - lr: 0.0050\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wgvgnAvGjtmk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}